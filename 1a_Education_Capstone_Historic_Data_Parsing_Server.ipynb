{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1a. Education Capstone Historic Data Parsing Server.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cfcastillo/DS-6-Notebooks/blob/main/1a_Education_Capstone_Historic_Data_Parsing_Server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Education Capstone - Supplementary File Processing"
      ],
      "metadata": {
        "id": "yob4MNvZP6fd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmtnA4AUIyGl"
      },
      "source": [
        "# Overview\n",
        "\n",
        "ASEC years prior to 2019 are in flat file format and need to be parsed into csv format so that they can be used in the main capstone project notebook and so that we can combine them into datasets for historic trend analysis.\n",
        "\n",
        "1. Data for 2011 to 2018 will be parsed into CSV\n",
        "1. Data will be copied to the capstone data folder.\n",
        "1. Data will be combined into a single dataframe, with year, to run trend analysis.\n",
        "1. Data will contain only target and predictor columns plus year.\n",
        "\n",
        "Data Source\n",
        "* [2018 Survey - dat](https://www.census.gov/data/datasets/time-series/demo/cps/cps-asec.2018.html) - Need to convert to csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZqcwQ9-oz9P"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAiyA1HSo2I-",
        "outputId": "8ef6dc31-15a0-41cb-82cd-132677ae9813"
      },
      "source": [
        "# grab the imports needed for the project\n",
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnX92409Rwc_"
      },
      "source": [
        "## Setup Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU2bfMD3m3ua"
      },
      "source": [
        "# Expected values are: ellie, amy, cecilia - lowercase\n",
        "team_member = 'cecilia'\n",
        "\n",
        "# Root drive path\n",
        "if team_member in ['amy','ellie']:\n",
        "  root_drive = '/content/drive/MyDrive/'\n",
        "else: # Cecilia\n",
        "  root_drive = '/content/drive/MyDrive/Student Folder - Cecilia/Projects/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-wvWLh2kS8S",
        "outputId": "e1155407-8c04-4b66-aa48-12607ebfed43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YK093isRXEP"
      },
      "source": [
        "# Combine 2014 data\n",
        "\n",
        "2014 was produced in two datasets so they need to be concatenated together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg_KJcEPRjpU"
      },
      "source": [
        "# Concat data from different years into single dataframe for trend analysis\n",
        "path = root_drive + 'Capstone/Data/ASEC/asecpub14csv/'\n",
        "file_names = glob.glob(path + \"pp*.csv\")\n",
        "li = []\n",
        "for filename in file_names:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "# Append all files in folder\n",
        "combined_data = pd.concat(li, axis=0, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WprXzqWXQ1u"
      },
      "source": [
        "export_path = path + 'pppub14.csv'\n",
        "combined_data.to_csv(export_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6OIKvWxo3cz"
      },
      "source": [
        "# Combine Trend Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unqUAHX7kNhe"
      },
      "source": [
        "# Concat data from different years into single dataframe for trend analysis\n",
        "trends_path = root_drive + 'Capstone/Data/FinalData/Trends/'\n",
        "trends_file_names = glob.glob(trends_path + \"*v3.csv\")\n",
        "li = []\n",
        "for filename in trends_file_names:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "# Append all files in folder\n",
        "trends_data = pd.concat(li, axis=0, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQvuAqUwpdOW",
        "outputId": "3bd62cd5-f415-4208-e353-1341af215a74"
      },
      "source": [
        "# trends_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(395167, 51)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt0fpB7ipoqH"
      },
      "source": [
        "# trends_data.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeobYW0rpZeF"
      },
      "source": [
        "\n",
        "# Export to CSV for teammates to use in EDA\n",
        "export_path = trends_path + 'asec_trend_v3.csv'\n",
        "trends_data.to_csv(export_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YAGFC1ir0j3"
      },
      "source": [
        "# Parse 2018 and Earlier Data\n",
        "\n",
        "*Note: all parsing was done on a local Jupyter notebook due to the large data size to avoid having to upload source files to Google Drive.*\n",
        "\n",
        "[Here is a link to a GitHub copy of the parsing notebook.](https://github.com/cfcastillo/DS-6-Notebooks/blob/main/Education%20Capstone%20Historic%20Data%20Parsing.ipynb)\n",
        "\n",
        "Per the data dictionary, household, family, and person data are all in the same file. So will need to split them out to import into the main notebook.\n",
        "\n",
        "[Useful link on how to use Pandas to parse fix width files.](https://towardsdatascience.com/parsing-fixed-width-text-files-with-pandas-f1db8f737276)"
      ]
    }
  ]
}